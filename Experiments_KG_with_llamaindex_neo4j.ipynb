{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07bd8f95afc442b9939560827ef788a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bde76bb40fa42b49f5fdb25ae7682df",
              "IPY_MODEL_ee9c5bcc086645409e176af3de72cbcd",
              "IPY_MODEL_d6eb26894848470493c489add4f771f1"
            ],
            "layout": "IPY_MODEL_92de6bca5f784832958b017542cd43a3"
          }
        },
        "0bde76bb40fa42b49f5fdb25ae7682df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b22578d792e4fed9874bc131a5c5aa2",
            "placeholder": "​",
            "style": "IPY_MODEL_e87769996fa54b36a521f6851e20edce",
            "value": "Parsing nodes: 100%"
          }
        },
        "ee9c5bcc086645409e176af3de72cbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08f9e3934a3349ada9efd23f74b1470b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51be9293f9264783b95f9ca6898b34ff",
            "value": 1
          }
        },
        "d6eb26894848470493c489add4f771f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45f4dd388d2b4e0aba8e97c64149cc57",
            "placeholder": "​",
            "style": "IPY_MODEL_11309179b70140aa94576e786601fc61",
            "value": " 1/1 [00:00&lt;00:00, 11.33it/s]"
          }
        },
        "92de6bca5f784832958b017542cd43a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b22578d792e4fed9874bc131a5c5aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e87769996fa54b36a521f6851e20edce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08f9e3934a3349ada9efd23f74b1470b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51be9293f9264783b95f9ca6898b34ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45f4dd388d2b4e0aba8e97c64149cc57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11309179b70140aa94576e786601fc61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "961c873053e14da892c52cdd0be6a428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bb9ed9615984fdeb0344aec33f4c002",
              "IPY_MODEL_80d600fe5b144fc3b93e613d8510b644",
              "IPY_MODEL_84b44118b25841988e939f651f8757b2"
            ],
            "layout": "IPY_MODEL_60637cf48cdf45c19aaa5c9f4333e37f"
          }
        },
        "3bb9ed9615984fdeb0344aec33f4c002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eddb78864dd40ed99cae64cca8fefa8",
            "placeholder": "​",
            "style": "IPY_MODEL_1a0228674b464d829feeb37f6757b94b",
            "value": "Parsing nodes: 100%"
          }
        },
        "80d600fe5b144fc3b93e613d8510b644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4d837d4c73a481a95f15aa7b31825ba",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0672a6c9b2764955b530cedaabfa0627",
            "value": 1
          }
        },
        "84b44118b25841988e939f651f8757b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c9d372191424368a74ec78799eb24ff",
            "placeholder": "​",
            "style": "IPY_MODEL_267546dc7165440d942e1eecee94d213",
            "value": " 1/1 [00:00&lt;00:00, 12.32it/s]"
          }
        },
        "60637cf48cdf45c19aaa5c9f4333e37f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eddb78864dd40ed99cae64cca8fefa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a0228674b464d829feeb37f6757b94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4d837d4c73a481a95f15aa7b31825ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0672a6c9b2764955b530cedaabfa0627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c9d372191424368a74ec78799eb24ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "267546dc7165440d942e1eecee94d213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86e0b3f975bd4dc18b2fb9097ffbea6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d631484b62240d38aed49752ba8208d",
              "IPY_MODEL_5c7f9563f89345258ec23354643f619d",
              "IPY_MODEL_3449d3a2350e4ba68c48763da0453dc6"
            ],
            "layout": "IPY_MODEL_6554b4423e18489286ffe6f561ba31a8"
          }
        },
        "0d631484b62240d38aed49752ba8208d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d24667b68ec4ac6af266254c8b29d9d",
            "placeholder": "​",
            "style": "IPY_MODEL_5716eb47f196469194243a1040e17685",
            "value": "Parsing nodes: 100%"
          }
        },
        "5c7f9563f89345258ec23354643f619d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c27e32d29184462a7f72f291a3b6caa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0df74b6dd5f840989737381805e5ce9d",
            "value": 1
          }
        },
        "3449d3a2350e4ba68c48763da0453dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a8ba7ef5a4f477c8a2bee7a59677ce9",
            "placeholder": "​",
            "style": "IPY_MODEL_62bd0bb8bcf641f5a61fb8f8515bd6d0",
            "value": " 1/1 [00:00&lt;00:00, 19.21it/s]"
          }
        },
        "6554b4423e18489286ffe6f561ba31a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d24667b68ec4ac6af266254c8b29d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5716eb47f196469194243a1040e17685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c27e32d29184462a7f72f291a3b6caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0df74b6dd5f840989737381805e5ce9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a8ba7ef5a4f477c8a2bee7a59677ce9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62bd0bb8bcf641f5a61fb8f8515bd6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook belongs to a knowledge graph evalutation project -- some link."
      ],
      "metadata": {
        "id": "Y-3lalkuXoQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Test out LLM LLM Path Extractors for Knowledge Graph Construction from Llamaindex\n"
      ],
      "metadata": {
        "id": "RUdtPYM9YWU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up and imports"
      ],
      "metadata": {
        "id": "1SFfFDYT9nf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Line Wrapping in Colab\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "jsh28ivNIR2C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# An elegant way to view JSON data\n",
        "import json\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def view_json(data):\n",
        "    \"\"\"\n",
        "    Display JSON data as an interactive, collapsible tree in Google Colab.\n",
        "\n",
        "    Args:\n",
        "    data (dict or str): JSON data to display. Can be a Python dictionary or a JSON string.\n",
        "    \"\"\"\n",
        "    if isinstance(data, str):\n",
        "        data = json.loads(data)\n",
        "\n",
        "    # escape the semicolon using a backslash\n",
        "    html_content = \"\"\"\n",
        "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/jsoneditor/9.9.2/jsoneditor.min.js\"></script>\n",
        "    <link href=\"https://cdnjs.cloudflare.com/ajax/libs/jsoneditor/9.9.2/jsoneditor.min.css\" rel=\"stylesheet\" type=\"text/css\">\n",
        "    <div id=\"jsoneditor\" style=\"width: 100%%; height: 400px;\"></div>\n",
        "    <script>\n",
        "        var container = document.getElementById(\"jsoneditor\");\n",
        "        var options = {\n",
        "            mode: 'tree',\n",
        "            modes: ['tree', 'view', 'form', 'code', 'text', 'preview'],\n",
        "            onError: function (err) {\n",
        "                alert(err.toString());\n",
        "            }\n",
        "        };\n",
        "        var editor = new JSONEditor(container, options);\n",
        "        var json = %s;\n",
        "        editor.set(json);\n",
        "        editor.expandAll();\n",
        "    </script>\n",
        "    \"\"\" % json.dumps(data)\n",
        "\n",
        "    display(HTML(html_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VNxY5cYvLwAC",
        "outputId": "ae0e0034-9f69-423e-80c0-253579a2b50a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index llama-index-llms-perplexity pyvis wikipedia llama-index-graph-stores-neo4j\n",
        "\n"
      ],
      "metadata": {
        "id": "tAt-mHjiYTKf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9be91e5f-6726-4370-b1e9-c9753ae0af83",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index\n",
            "  Downloading llama_index-0.11.19-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-llms-perplexity\n",
            "  Downloading llama_index_llms_perplexity-0.2.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pyvis\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llama-index-graph-stores-neo4j\n",
            "  Downloading llama_index_graph_stores_neo4j-0.3.4-py3-none-any.whl.metadata (696 bytes)\n",
            "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama_index)\n",
            "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama_index)\n",
            "  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.12.0,>=0.11.19 (from llama_index)\n",
            "  Downloading llama_index_core-0.11.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama_index)\n",
            "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama_index)\n",
            "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.3.0,>=0.2.10 (from llama_index)\n",
            "  Downloading llama_index_llms_openai-0.2.15-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.2.2-py3-none-any.whl.metadata (678 bytes)\n",
            "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting nltk>3.8.1 (from llama_index)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.1.4)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.3.0)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.4.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
            "Collecting neo4j<6.0.0,>=5.16.0 (from llama-index-graph-stores-neo4j)\n",
            "  Downloading neo4j-5.25.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9.6->pyvis) (3.0.1)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.4.0,>=0.3.4->llama_index)\n",
            "  Downloading openai-1.52.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.19->llama_index) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (3.10.10)\n",
            "Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (1.2.14)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (2024.6.1)\n",
            "Collecting httpx (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (1.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (2.9.2)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (1.16.0)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama_index)\n",
            "  Downloading llama_cloud-0.1.4-py3-none-any.whl.metadata (814 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.2.2)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama_index)\n",
            "  Downloading llama_parse-0.5.10-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j<6.0.0,>=5.16.0->llama-index-graph-stores-neo4j) (2024.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama_index) (2024.9.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (4.0.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama_index) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama_index)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.19->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.19->llama_index) (2.23.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.19->llama_index) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.19->llama_index) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (0.2.0)\n",
            "Downloading llama_index-0.11.19-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_llms_perplexity-0.2.1-py3-none-any.whl (5.2 kB)\n",
            "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_graph_stores_neo4j-0.3.4-py3-none-any.whl (12 kB)\n",
            "Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_core-0.11.19-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl (10 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.2.15-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.2.2-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading neo4j-5.25.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.6/296.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_cloud-0.1.4-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.8/176.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.5.10-py3-none-any.whl (12 kB)\n",
            "Downloading openai-1.52.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=b42b4ffdd9a0c06eba26baf892eca7dba1852809291db576f7e6b74492ff514b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: striprtf, dirtyjson, tenacity, pypdf, nltk, neo4j, mypy-extensions, marshmallow, jiter, jedi, h11, wikipedia, typing-inspect, tiktoken, httpcore, pyvis, httpx, dataclasses-json, openai, llama-index-core, llama-cloud, llama-parse, llama-index-readers-file, llama-index-llms-perplexity, llama-index-llms-openai, llama-index-legacy, llama-index-indices-managed-llama-cloud, llama-index-graph-stores-neo4j, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama_index\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed dataclasses-json-0.6.7 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jedi-0.19.1 jiter-0.6.1 llama-cloud-0.1.4 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-core-0.11.19 llama-index-embeddings-openai-0.2.5 llama-index-graph-stores-neo4j-0.3.4 llama-index-indices-managed-llama-cloud-0.4.0 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.2.15 llama-index-llms-perplexity-0.2.1 llama-index-multi-modal-llms-openai-0.2.2 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.2 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.10 llama_index-0.11.19 marshmallow-3.23.0 mypy-extensions-1.0.0 neo4j-5.25.0 nltk-3.9.1 openai-1.52.0 pypdf-4.3.1 pyvis-0.3.2 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.8.0 typing-inspect-0.9.0 wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Document, PropertyGraphIndex\n",
        "from llama_index.core.indices.property_graph import (\n",
        "    SimpleLLMPathExtractor,\n",
        "    SchemaLLMPathExtractor,\n",
        "    DynamicLLMPathExtractor,\n",
        ")\n",
        "from llama_index.llms.perplexity import Perplexity\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core import Settings\n",
        "\n",
        "import wikipedia\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "X8gT6vPr9yIN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7708cabb-8efa-4c3c-c941-fe74a8d3b92a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "BKFR8Bcn9-an",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d9aab6a4-7919-4945-b1cd-09ea9040652b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup LLM backend\n",
        "\n",
        "*   We are using llama 3.1 chat model with a context window of 131,072 tokens\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ff99N_o2-Czj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "pplx_api_key = userdata.get('PPLX_API_KEY')\n",
        "\n",
        "llm = Perplexity(\n",
        "    api_key=pplx_api_key,\n",
        "    model=\"llama-3.1-sonar-large-128k-chat\",\n",
        "    temperature=0.5,\n",
        "    # max_retries = 3,\n",
        "    # additional_kwargs = {\"timeout\": 60}\n",
        ")\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.chunk_size = 2048\n",
        "Settings.chunk_overlap = 20"
      ],
      "metadata": {
        "id": "ok3N5doM-FOc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1d7cef66-2010-4bb0-fc69-610759503880"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "C32MXUV-cq8X",
        "outputId": "d4196e34-63e6-4b0c-aebd-90b403d42215"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__class_vars__',\n",
              " '__copy__',\n",
              " '__deepcopy__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__fields__',\n",
              " '__fields_set__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__get_pydantic_core_schema__',\n",
              " '__get_pydantic_json_schema__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pretty__',\n",
              " '__private_attributes__',\n",
              " '__pydantic_complete__',\n",
              " '__pydantic_core_schema__',\n",
              " '__pydantic_custom_init__',\n",
              " '__pydantic_decorators__',\n",
              " '__pydantic_extra__',\n",
              " '__pydantic_fields_set__',\n",
              " '__pydantic_generic_metadata__',\n",
              " '__pydantic_init_subclass__',\n",
              " '__pydantic_parent_namespace__',\n",
              " '__pydantic_post_init__',\n",
              " '__pydantic_private__',\n",
              " '__pydantic_root_model__',\n",
              " '__pydantic_serializer__',\n",
              " '__pydantic_validator__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__repr_args__',\n",
              " '__repr_name__',\n",
              " '__repr_str__',\n",
              " '__rich_repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__signature__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_achat',\n",
              " '_acomplete',\n",
              " '_as_query_component',\n",
              " '_astream_chat',\n",
              " '_astream_complete',\n",
              " '_calculate_keys',\n",
              " '_chat',\n",
              " '_check_frozen',\n",
              " '_complete',\n",
              " '_copy_and_set_values',\n",
              " '_extend_messages',\n",
              " '_extend_prompt',\n",
              " '_get_all_kwargs',\n",
              " '_get_context_window',\n",
              " '_get_messages',\n",
              " '_get_prompt',\n",
              " '_get_value',\n",
              " '_is_chat_model',\n",
              " '_iter',\n",
              " '_log_template_data',\n",
              " '_parse_output',\n",
              " '_stream_chat',\n",
              " '_stream_complete',\n",
              " 'achat',\n",
              " 'acomplete',\n",
              " 'additional_kwargs',\n",
              " 'api_base',\n",
              " 'api_key',\n",
              " 'apredict',\n",
              " 'apredict_and_call',\n",
              " 'as_query_component',\n",
              " 'as_structured_llm',\n",
              " 'astream',\n",
              " 'astream_chat',\n",
              " 'astream_complete',\n",
              " 'astream_structured_predict',\n",
              " 'astructured_predict',\n",
              " 'callback_manager',\n",
              " 'chat',\n",
              " 'check_callback_manager',\n",
              " 'check_prompts',\n",
              " 'class_name',\n",
              " 'complete',\n",
              " 'completion_to_prompt',\n",
              " 'construct',\n",
              " 'context_window',\n",
              " 'convert_chat_messages',\n",
              " 'copy',\n",
              " 'custom_model_dump',\n",
              " 'dict',\n",
              " 'from_dict',\n",
              " 'from_json',\n",
              " 'from_orm',\n",
              " 'headers',\n",
              " 'json',\n",
              " 'max_retries',\n",
              " 'max_tokens',\n",
              " 'messages_to_prompt',\n",
              " 'metadata',\n",
              " 'model',\n",
              " 'model_computed_fields',\n",
              " 'model_config',\n",
              " 'model_construct',\n",
              " 'model_copy',\n",
              " 'model_dump',\n",
              " 'model_dump_json',\n",
              " 'model_extra',\n",
              " 'model_fields',\n",
              " 'model_fields_set',\n",
              " 'model_json_schema',\n",
              " 'model_parametrized_name',\n",
              " 'model_post_init',\n",
              " 'model_rebuild',\n",
              " 'model_validate',\n",
              " 'model_validate_json',\n",
              " 'model_validate_strings',\n",
              " 'output_parser',\n",
              " 'parse_file',\n",
              " 'parse_obj',\n",
              " 'parse_raw',\n",
              " 'predict',\n",
              " 'predict_and_call',\n",
              " 'pydantic_program_mode',\n",
              " 'query_wrapper_prompt',\n",
              " 'schema',\n",
              " 'schema_json',\n",
              " 'set_completion_to_prompt',\n",
              " 'set_messages_to_prompt',\n",
              " 'stream',\n",
              " 'stream_chat',\n",
              " 'stream_complete',\n",
              " 'stream_structured_predict',\n",
              " 'structured_predict',\n",
              " 'system_prompt',\n",
              " 'temperature',\n",
              " 'to_dict',\n",
              " 'to_json',\n",
              " 'update_forward_refs',\n",
              " 'validate']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.0. Tests for LLM API references (chat)"
      ],
      "metadata": {
        "id": "A8iDQc0fTF39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out Perplexity API reference\n",
        "import requests\n",
        "\n",
        "url = \"https://api.perplexity.ai/chat/completions\"\n",
        "\n",
        "payload = {\n",
        "    \"model\": \"llama-3.1-sonar-large-128k-chat\",\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Be precise and concise.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"How many stars are there in our galaxy?\"\n",
        "        }\n",
        "    ],\n",
        "    # \"max_tokens\": 131072,\n",
        "    \"temperature\": 0.2,  # The amount of randomness in the response, valued between 0 inclusive and 2 exclusive. Higher values are more random, and lower values are more deterministic.\n",
        "    \"top_p\": 0.9,  # The nucleus sampling threshold, valued between 0 and 1 inclusive. For each subsequent token, the model considers the results of the tokens with top_p probability mass. We recommend either altering top_k or top_p, but not both.\n",
        "    \"return_citations\": False,\n",
        "    \"search_domain_filter\": [\"perplexity.ai\"],\n",
        "    \"return_images\": False,\n",
        "    \"return_related_questions\": False,\n",
        "    \"search_recency_filter\": \"month\",\n",
        "    \"top_k\": 0,  # The number of tokens to keep for highest top-k filtering, specified as an integer between 0 and 2048 inclusive. If set to 0, top-k filtering is disabled. We recommend either altering top_k or top_p, but not both.\n",
        "    \"stream\": False,  # Determines whether or not to incrementally stream the response with server-sent events with content-type: text/event-stream.\n",
        "    \"presence_penalty\": 0,  # A value between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. Incompatible with frequency_penalty.\n",
        "    \"frequency_penalty\": 1  # A multiplicative penalty greater than 0. Values greater than 1.0 penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. A value of 1.0 means no penalty. Incompatible with presence_penalty.\n",
        "}\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {pplx_api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
        "\n",
        "view_json(response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "HYK6WC7yG9-M",
        "outputId": "42f95a3c-87e6-4ca6-f78c-0a0063092709"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/jsoneditor/9.9.2/jsoneditor.min.js\"></script>\n",
              "    <link href=\"https://cdnjs.cloudflare.com/ajax/libs/jsoneditor/9.9.2/jsoneditor.min.css\" rel=\"stylesheet\" type=\"text/css\">\n",
              "    <div id=\"jsoneditor\" style=\"width: 100%; height: 400px;\"></div>\n",
              "    <script>\n",
              "        var container = document.getElementById(\"jsoneditor\");\n",
              "        var options = {\n",
              "            mode: 'tree',\n",
              "            modes: ['tree', 'view', 'form', 'code', 'text', 'preview'],\n",
              "            onError: function (err) {\n",
              "                alert(err.toString());\n",
              "            }\n",
              "        };\n",
              "        var editor = new JSONEditor(container, options);\n",
              "        var json = {\"id\": \"33be22c7-6e9a-48df-aadd-c0be2ef8082c\", \"model\": \"llama-3.1-sonar-large-128k-chat\", \"created\": 1729590595, \"usage\": {\"prompt_tokens\": 29, \"completion_tokens\": 35, \"total_tokens\": 64}, \"object\": \"chat.completion\", \"choices\": [{\"index\": 0, \"finish_reason\": \"stop\", \"message\": {\"role\": \"assistant\", \"content\": \"Estimates suggest that there are between 200 and 400 billion stars in the Milky Way galaxy. However, the exact number is still a subject of ongoing research and refinement.\"}, \"delta\": {\"role\": \"assistant\", \"content\": \"\"}}]};\n",
              "        editor.set(json);\n",
              "        editor.expandAll();\n",
              "    </script>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.json()['choices'][0]['message']['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QuhptFPyMor2",
        "outputId": "5f4c1cd4-cfd8-4c1c-8d4e-1b19c3971ccd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Estimates suggest that there are between 200 and 400 billion stars in the Milky Way galaxy. However, the exact number is still a subject of ongoing research and refinement.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out LlamaIndex wrapping of PPLX API chat\n",
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "messages_dict = [\n",
        "    {\"role\": \"system\", \"content\": \"Be precise and concise.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Tell me 5 sentences about Perplexity.\"},\n",
        "]\n",
        "messages = [ChatMessage(**msg) for msg in messages_dict]\n",
        "\n",
        "response = llm.chat(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "yWz3udfuSSbK",
        "outputId": "6c0c35ca-d396-4a5f-8736-8b3e9533657e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: Perplexity is a measure of how well a probability model predicts a test dataset. It is often used in natural language processing and information theory to evaluate the performance of language models. A lower perplexity score indicates better predictive performance, while a higher score suggests poorer performance. Perplexity is calculated as the exponential of the average negative log-likelihood of the test data. It provides a way to compare different models on their ability to predict unseen data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perplexity api turns out to has a low rate limit and it possibly not doesn't fit for KG extraction, so we just use OpneAI's service."
      ],
      "metadata": {
        "id": "UmhppSndkql5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up OpenAI model as the llm to request\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Set up global configurations\n",
        "llm = OpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.chunk_size = 2048\n",
        "Settings.chunk_overlap = 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bZ-VgwEFlCEB",
        "outputId": "854a5f7c-49a8-47d4-9d46-baadff8332c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out OpenAI integration in LlamaIndex for chat\n",
        "response = llm.chat(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "collapsed": true,
        "id": "g-Wz97XXliAj",
        "outputId": "eb0ddd48-7b7a-4378-ea46-3c0ed4e0b18e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: 1. Perplexity is a state of being confused or puzzled, often resulting from a lack of understanding or clarity.\n",
            "2. It can arise when faced with complex or contradictory information, leading to uncertainty or indecision.\n",
            "3. Perplexity is a common human experience that can occur in various situations, such as when trying to solve a difficult problem or make a challenging decision.\n",
            "4. It may also be a temporary feeling that can be resolved through further exploration, reflection, or seeking help from others.\n",
            "5. Coping with perplexity can help individuals develop critical thinking skills and deepen their understanding of complex issues.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for OpenAI api rate limits"
      ],
      "metadata": {
        "id": "LmGOZbTxzmDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "collapsed": true,
        "id": "57XcNPLLv_k1",
        "outputId": "059f824e-38ec-450f-a68f-2b56fecda8d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.with_raw_response.create(\n",
        "    messages=[{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Say this is a test\",\n",
        "    }],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "collapsed": true,
        "id": "KgDg0LFcoaCf",
        "outputId": "e2df370c-03ca-4803-b169-b13fabb4006b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access rate limit headers\n",
        "rate_limit_limit = response.headers.get('x-ratelimit-limit-requests')\n",
        "rate_limit_remaining = response.headers.get('x-ratelimit-remaining-requests')\n",
        "rate_limit_reset = response.headers.get('x-ratelimit-reset-requests')\n",
        "\n",
        "print(f\"Rate Limit: {rate_limit_limit}\")\n",
        "print(f\"Remaining Requests: {rate_limit_remaining}\")\n",
        "print(f\"Reset Time: {rate_limit_reset}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "qKPPkvWIy-DL",
        "outputId": "6ec56c5c-ad4c-4140-e4c4-b746f154e67e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate Limit: 10000\n",
            "Remaining Requests: 9999\n",
            "Reset Time: 6ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1. Fetch Raw Text from Wikipedia\n",
        "For starter, we use the wikipedia page for Heike Monogatari (English) as source text to generate KG from."
      ],
      "metadata": {
        "id": "mULEl8YRUndu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wikipedia_content(title):\n",
        "    try:\n",
        "        page = wikipedia.page(title)\n",
        "        return page.content\n",
        "    except wikipedia.exceptions.DisambiguationError as e:\n",
        "        print(f\"Disambiguation page. Options: {e.options}\")\n",
        "    except wikipedia.exceptions.PageError:\n",
        "        print(f\"Page '{title}' does not exist.\")\n",
        "    return None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zEMCZHc2VIMz",
        "outputId": "9960e125-9592-4f98-f172-74b37f41c634"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_title = \"The Tale of the Heike\"\n",
        "content = get_wikipedia_content(wiki_title)\n",
        "\n",
        "if content:\n",
        "    document = Document(text=content, metadata={\"title\": wiki_title})\n",
        "    print(\n",
        "        f\"Fetched content for '{wiki_title}' (length: {len(content)} characters)\"\n",
        "    )\n",
        "else:\n",
        "    print(\"Failed to fetch Wikipedia content.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "LHPtxm7FV84j",
        "outputId": "a01380f0-5a7e-4e94-9f46-4babb30b4bfa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched content for 'The Tale of the Heike' (length: 32837 characters)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document.text[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "irVv393fWm-7",
        "outputId": "609774d6-fda8-4fc9-e310-87cecad6abca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Tale of the Heike (平家物語, Heike Monogatari) is an epic account compiled prior to 1330 of the struggle between the Taira clan and Minamoto clan for control of Japan at the end of the 12th century in the Genpei War (1180–1185).\\nIt has been translated into English at least five times. The first translation was by Arthur Lindsay Sadler, in 1918–1921. A complete translation in nearly 800 pages by Hiroshi Kitagawa & Bruce T. Tsuchida was published in 1975. It was also translated by Helen McCullough'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2. SimpleLLMPathExtractor\n",
        "No predefined KG schemas, LLM extract it on the fly. For visualization, the KG is stored in a Neo4j database for querying."
      ],
      "metadata": {
        "id": "tEsCaLVPZDLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neo4j DB set up\n",
        "from llama_index.graph_stores.neo4j import Neo4jPGStore\n",
        "\n",
        "username=\"neo4j\"\n",
        "password=userdata.get('PW_NEO4J')\n",
        "url=userdata.get('URI_NEO4J')\n",
        "\n",
        "graph_store = Neo4jPGStore(\n",
        "    username=username,\n",
        "    password=password,\n",
        "    url=url,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QV3PTAGh2O6H",
        "outputId": "494b5400-7226-4691-ff39-52963e6c91c2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg_extractor = SimpleLLMPathExtractor(\n",
        "    llm=llm, max_paths_per_chunk=20, num_workers=4\n",
        ")\n",
        "\n",
        "simple_index = PropertyGraphIndex.from_documents(\n",
        "    [document],\n",
        "    llm=llm,\n",
        "    embed_kg_nodes=False,\n",
        "    kg_extractors=[kg_extractor],\n",
        "    property_graph_store=graph_store,\n",
        "    show_progress=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "07bd8f95afc442b9939560827ef788a9",
            "0bde76bb40fa42b49f5fdb25ae7682df",
            "ee9c5bcc086645409e176af3de72cbcd",
            "d6eb26894848470493c489add4f771f1",
            "92de6bca5f784832958b017542cd43a3",
            "2b22578d792e4fed9874bc131a5c5aa2",
            "e87769996fa54b36a521f6851e20edce",
            "08f9e3934a3349ada9efd23f74b1470b",
            "51be9293f9264783b95f9ca6898b34ff",
            "45f4dd388d2b4e0aba8e97c64149cc57",
            "11309179b70140aa94576e786601fc61"
          ]
        },
        "id": "k2ue6vpNZUSi",
        "outputId": "743efb3d-639e-491a-d19c-dd07c9711369"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07bd8f95afc442b9939560827ef788a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting paths from text: 100%|██████████| 5/5 [00:10<00:00,  2.11s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.3 SchemaLLMPathExtractor\n",
        "It seems that the KG extracted without inital ontology is a mess. the definition of the schema of a KG is very subjective and in the end, KG is a tool designated to the envisionned application."
      ],
      "metadata": {
        "id": "-RspxMlklelO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "\n",
        "# best practice to use upper-case\n",
        "entities = Literal[\"CLAN\", \"BUDDHIST_TEMPLE\", \"IMPERIAL_COURT\", \"PERSON\", \"EVENT\", \"CHAPTER\"]\n",
        "relations = Literal[\"HAS_MEMBER\", \"HAS_PARENT\", \"HAS_SPOUSE\", \"HAS_CHILD\", \"HAS_PARTICIPANT\", \"IS_PART_OF\", \"MENTIONS_PERSON\", \"DESCRIBES_EVENT\"]\n",
        "\n",
        "# define which entities can have which relations\n",
        "validation_schema = [\n",
        "    (\"CLAN\", \"HAS_MEMBER\", \"PERSON\"),\n",
        "    (\"BUDDHIST_TEMPLE\", \"HAS_MEMBER\", \"PERSON\"),\n",
        "    (\"IMPERIAL_COURT\", \"HAS_MEMBER\", \"PERSON\"),\n",
        "    (\"PERSON\", \"HAS_PARENT\", \"PERSON\"),\n",
        "    (\"PERSON\", \"HAS_SPOUSE\", \"PERSON\"),\n",
        "    (\"PERSON\", \"HAS_CHILD\", \"PERSON\"),\n",
        "    (\"EVENT\", \"HAS_PARTICIPANT\", \"PERSON\"),\n",
        "    (\"EVENT\", \"IS_PART_OF\", \"EVENT\"),\n",
        "    (\"CHAPTER\", \"MENTIONS_PERSON\", \"PERSON\"),\n",
        "    (\"CHAPTER\", \"DESCRIBES_EVENT\", \"EVENT\"),\n",
        "]\n",
        "\n",
        "entity_props = [\n",
        "    (\"FAMILY_NAME\", \"the family name of a PERSON\"),\n",
        "    (\"GIVEN_NAME\", \"the given name of a PERSON\"),\n",
        "    (\"BIRTH_DATE\", \"the birth date of a PERSON\"),\n",
        "    (\"DEATH_DATE\", \"the death date of a PERSON\"),\n",
        "    (\"DATE_OF_OCCURRENCE\", \"the date of occurrence of an EVENT\"),\n",
        "    (\"PLACE_OF_OCCURRENCE\", \"the place of occurrence of an EVENT\"),\n",
        "    (\"TITLE\", \"the title of a CHAPTER\"),\n",
        "]\n",
        "\n",
        "kg_extractor = SchemaLLMPathExtractor(\n",
        "    llm=llm,\n",
        "    possible_entities=entities,\n",
        "    possible_relations=relations,\n",
        "    possible_entity_props=entity_props,\n",
        "    kg_validation_schema=validation_schema,\n",
        "    # if false, allows for values outside of the schema\n",
        "    # useful for using the schema as a suggestion\n",
        "    strict=True,\n",
        "    num_workers=4,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "l8E-AZmcnlKN",
        "outputId": "3c80a2b4-9c19-4c44-85d5-3e1836664f0e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = PropertyGraphIndex.from_documents(\n",
        "    [document],\n",
        "    llm=llm,\n",
        "    kg_extractors=[kg_extractor],\n",
        "    embed_kg_nodes=False,\n",
        "    property_graph_store=graph_store,\n",
        "    show_progress=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414,
          "referenced_widgets": [
            "961c873053e14da892c52cdd0be6a428",
            "3bb9ed9615984fdeb0344aec33f4c002",
            "80d600fe5b144fc3b93e613d8510b644",
            "84b44118b25841988e939f651f8757b2",
            "60637cf48cdf45c19aaa5c9f4333e37f",
            "4eddb78864dd40ed99cae64cca8fefa8",
            "1a0228674b464d829feeb37f6757b94b",
            "e4d837d4c73a481a95f15aa7b31825ba",
            "0672a6c9b2764955b530cedaabfa0627",
            "8c9d372191424368a74ec78799eb24ff",
            "267546dc7165440d942e1eecee94d213"
          ]
        },
        "id": "FMJfVVo_ok7k",
        "outputId": "4aabf8c7-d3d6-453d-d017-7d3987a94bd5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "961c873053e14da892c52cdd0be6a428"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting paths from text with schema: 100%|██████████| 5/5 [00:59<00:00, 11.91s/it]\n",
            "ERROR:neo4j.io:Failed to write data to connection ResolvedIPv4Address(('34.126.171.25', 7687)) (ResolvedIPv4Address(('34.126.171.25', 7687)))\n",
            "ERROR:neo4j.io:Failed to write data to connection IPv4Address(('0e1f165c.databases.neo4j.io', 7687)) (ResolvedIPv4Address(('34.126.171.25', 7687)))\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: __Node__)} {position: line: 1, column: 11, offset: 10} for query: \"MATCH (e: __Node__) WHERE e.id IS NOT NULL AND e.id in $ids \\n        WITH e\\n        RETURN e.id AS name,\\n               [l in labels(e) WHERE l <> '__Entity__' | l][0] AS type,\\n               e{.* , embedding: Null, id: Null} AS properties\\n        \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: __Node__)} {position: line: 1, column: 11, offset: 10} for query: \"MATCH (e: __Node__) WHERE e.id IS NOT NULL AND e.id in $ids \\n        WITH e\\n        RETURN e.id AS name,\\n               [l in labels(e) WHERE l <> '__Entity__' | l][0] AS type,\\n               e{.* , embedding: Null, id: Null} AS properties\\n        \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple schema with simple source document\n",
        "\n",
        "wiki_title = \"List of The Tale of the Heike characters\"\n",
        "content = get_wikipedia_content(wiki_title)\n",
        "\n",
        "if content:\n",
        "    document = Document(text=content, metadata={\"title\": wiki_title})\n",
        "    print(\n",
        "        f\"Fetched content for '{wiki_title}' (length: {len(content)} characters)\"\n",
        "    )\n",
        "else:\n",
        "    print(\"Failed to fetch Wikipedia content.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "n0zmz3hIcEy5",
        "outputId": "63afa5ff-ef9b-45d0-cffc-8516048449a8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched content for 'List of The Tale of the Heike characters' (length: 10413 characters)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document.text[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "kV3oCiJfct5u",
        "outputId": "bdd0ea18-bf76-4ea2-93ea-ab633394217b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a list of the characters that appear in The Tale of the Heike.\\n\\n\\n== A ==\\nArio, a loyal page boy in the service of Shunkan, who looked after him since he was young.  He sought Shunkan out at Kikai-ga-shima and looked after him during his exile.\\nTaira no Atsumori, a young warrior known for his death in single combat at the hands of Kumagae no Jirô Naozane.  He was well known for his skill with the flute.\\n\\n\\n== B ==\\nSaito Musashibo Benkei, a Sohei who served Minamoto no Yoshitsune.  He is kn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(document.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "RSLFVl-Zc0Q9",
        "outputId": "b7c6bd08-8ca2-4d53-a214-f70ea938ab7e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'List of The Tale of the Heike characters'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.chunk_size = 200\n",
        "Settings.chunk_overlap = 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "dYy3IUlxhOc4",
        "outputId": "d730b1f2-7516-403b-84b9-53c2a23e4e08"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entities = Literal[\"PERSON\", \"CLAN\"]\n",
        "relations = Literal[\"HAS_MEMBER\", \"HAS_PARENT\", \"HAS_SPOUSE\"]\n",
        "\n",
        "validation_schema = [\n",
        "    (\"CLAN\", \"HAS_MEMBER\", \"PERSON\"),\n",
        "    (\"PERSON\", \"HAS_PARENT\", \"PERSON\"),\n",
        "    (\"PERSON\", \"HAS_SPOUSE\", \"PERSON\"),\n",
        "]\n",
        "\n",
        "entity_props = [\n",
        "    (\"FAMILY_NAME\", \"the family name of a PERSON\"),\n",
        "    (\"GIVEN_NAME\", \"the given name of a PERSON\"),\n",
        "]\n",
        "\n",
        "kg_extractor = SchemaLLMPathExtractor(\n",
        "    llm=llm,\n",
        "    possible_entities=entities,\n",
        "    possible_relations=relations,\n",
        "    possible_entity_props=entity_props,\n",
        "    kg_validation_schema=validation_schema,\n",
        "    strict=True,\n",
        "    num_workers=4,\n",
        "    max_triplets_per_chunk=20,\n",
        ")\n",
        "\n",
        "index = PropertyGraphIndex.from_documents(\n",
        "    [document],\n",
        "    llm=llm,\n",
        "    kg_extractors=[kg_extractor],\n",
        "    embed_kg_nodes=False,\n",
        "    property_graph_store=graph_store,\n",
        "    show_progress=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "86e0b3f975bd4dc18b2fb9097ffbea6e",
            "0d631484b62240d38aed49752ba8208d",
            "5c7f9563f89345258ec23354643f619d",
            "3449d3a2350e4ba68c48763da0453dc6",
            "6554b4423e18489286ffe6f561ba31a8",
            "8d24667b68ec4ac6af266254c8b29d9d",
            "5716eb47f196469194243a1040e17685",
            "2c27e32d29184462a7f72f291a3b6caa",
            "0df74b6dd5f840989737381805e5ce9d",
            "7a8ba7ef5a4f477c8a2bee7a59677ce9",
            "62bd0bb8bcf641f5a61fb8f8515bd6d0"
          ]
        },
        "id": "KUI2Dgg8dO-7",
        "outputId": "e72ba57f-52d2-4022-ece7-c3c40f1db335"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86e0b3f975bd4dc18b2fb9097ffbea6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting paths from text with schema: 100%|██████████| 18/18 [00:25<00:00,  1.40s/it]\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: __Node__)} {position: line: 1, column: 11, offset: 10} for query: \"MATCH (e: __Node__) WHERE e.id IS NOT NULL AND e.id in $ids \\n        WITH e\\n        RETURN e.id AS name,\\n               [l in labels(e) WHERE l <> '__Entity__' | l][0] AS type,\\n               e{.* , embedding: Null, id: Null} AS properties\\n        \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: id)} {position: line: 1, column: 29, offset: 28} for query: \"MATCH (e: __Node__) WHERE e.id IS NOT NULL AND e.id in $ids \\n        WITH e\\n        RETURN e.id AS name,\\n               [l in labels(e) WHERE l <> '__Entity__' | l][0] AS type,\\n               e{.* , embedding: Null, id: Null} AS properties\\n        \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: id)} {position: line: 1, column: 50, offset: 49} for query: \"MATCH (e: __Node__) WHERE e.id IS NOT NULL AND e.id in $ids \\n        WITH e\\n        RETURN e.id AS name,\\n               [l in labels(e) WHERE l <> '__Entity__' | l][0] AS type,\\n               e{.* , embedding: Null, id: Null} AS properties\\n        \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: id)} {position: line: 3, column: 18, offset: 93} for query: \"MATCH (e: __Node__) WHERE e.id IS NOT NULL AND e.id in $ids \\n        WITH e\\n        RETURN e.id AS name,\\n               [l in labels(e) WHERE l <> '__Entity__' | l][0] AS type,\\n               e{.* , embedding: Null, id: Null} AS properties\\n        \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: __Node__)} {position: line: 1, column: 11, offset: 10} for query: \"MATCH (e: __Node__) WHERE e.id IS NOT NULL AND e.id in $ids \\n        WITH e\\n        RETURN e.id AS name,\\n               [l in labels(e) WHERE l <> '__Entity__' | l][0] AS type,\\n               e{.* , embedding: Null, id: Null} AS properties\\n        \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: id)} {position: line: 1, column: 29, offset: 28} for query: \"MATCH (e: __Node__) WHERE e.id IS NOT NULL AND e.id in $ids \\n        WITH e\\n        RETURN e.id AS name,\\n               [l in labels(e) WHERE l <> '__Entity__' | l][0] AS type,\\n               e{.* , embedding: Null, id: Null} AS properties\\n        \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: id)} {position: line: 1, column: 50, offset: 49} for query: \"MATCH (e: __Node__) WHERE e.id IS NOT NULL AND e.id in $ids \\n        WITH e\\n        RETURN e.id AS name,\\n               [l in labels(e) WHERE l <> '__Entity__' | l][0] AS type,\\n               e{.* , embedding: Null, id: Null} AS properties\\n        \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: id)} {position: line: 3, column: 18, offset: 93} for query: \"MATCH (e: __Node__) WHERE e.id IS NOT NULL AND e.id in $ids \\n        WITH e\\n        RETURN e.id AS name,\\n               [l in labels(e) WHERE l <> '__Entity__' | l][0] AS type,\\n               e{.* , embedding: Null, id: Null} AS properties\\n        \"\n"
          ]
        }
      ]
    }
  ]
}